{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial para instalar y usar el modelo de limpieza de fachadas"
      ],
      "metadata": {
        "id": "AOBoHdihIPc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalar dependencias"
      ],
      "metadata": {
        "id": "l3VPkXFVIYU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar versión compatible (ejemplo: 2.5.1 con CUDA 12.1)\n",
        "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpiMM0pPAiw2",
        "outputId": "0de4f598-81db-46a7-f43f-7274897bbe18"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (75.2.0)\n",
            "Collecting sympy==1.13.1 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.1) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
            "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.201-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.201-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.201 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml tqdm numpy==1.26.4 easydict==1.9.0 scikit-image scikit-learn \\\n",
        "            opencv-python tensorflow joblib matplotlib pandas \\\n",
        "            albumentations==0.5.2 \\\n",
        "            pytorch-lightning==1.2.9 tabulate \\\n",
        "            kornia==0.5.0 webdataset packaging \\\n",
        "            wldhx.yadisk-direct timm \\\n",
        "            #  hydra-core==1.1.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UVwsdqGL7VOo",
        "outputId": "f29d0801-5546-4fb3-b401-08febac87671"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting easydict==1.9.0\n",
            "  Downloading easydict-1.9.tar.gz (6.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting albumentations==0.5.2\n",
            "  Downloading albumentations-0.5.2-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pytorch-lightning==1.2.9\n",
            "  Downloading pytorch_lightning-1.2.9-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Collecting kornia==0.5.0\n",
            "  Downloading kornia-0.5.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting webdataset\n",
            "  Downloading webdataset-1.0.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (25.0)\n",
            "Collecting wldhx.yadisk-direct\n",
            "  Downloading wldhx.yadisk_direct-0.0.6-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.19)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from albumentations==0.5.2) (1.16.1)\n",
            "Collecting imgaug>=0.4.0 (from albumentations==0.5.2)\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from albumentations==0.5.2) (4.12.0.88)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning==1.2.9) (2.5.1+cu121)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning==1.2.9) (1.0.0)\n",
            "Requirement already satisfied: fsspec>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.2.9) (2025.3.0)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning==1.2.9) (2.19.0)\n",
            "Collecting torchmetrics==0.2.0 (from pytorch-lightning==1.2.9)\n",
            "  Downloading torchmetrics-0.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.8.28)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Collecting braceexpand (from webdataset)\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.20.1+cu121)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.34.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.2.9) (3.12.15)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.12/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (2.1.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python-headless>=4.1.1 (from albumentations==0.5.2)\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.9) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.9) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.9) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (3.19.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4->pytorch-lightning==1.2.9) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4->pytorch-lightning==1.2.9) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=1.4->pytorch-lightning==1.2.9) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.9)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch-lightning==1.2.9) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch-lightning==1.2.9) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch-lightning==1.2.9) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch-lightning==1.2.9) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch-lightning==1.2.9) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch-lightning==1.2.9) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch-lightning==1.2.9) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.2.9) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albumentations-0.5.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-1.2.9-py3-none-any.whl (841 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.9/841.9 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.5.0-py2.py3-none-any.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.5/271.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-0.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdataset-1.0.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wldhx.yadisk_direct-0.0.6-py3-none-any.whl (4.5 kB)\n",
            "Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Building wheels for collected packages: easydict\n",
            "  Building wheel for easydict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for easydict: filename=easydict-1.9-py3-none-any.whl size=6344 sha256=aaf1cb07ff3c6936cbf01e145ecb2fbaa18716f6b0a88ed6e835a3214943747e\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/5a/f6/81107b9d8caf5a5fcdd6f0b23419e6524dcda33fe2e74da012\n",
            "Successfully built easydict\n",
            "Installing collected packages: easydict, braceexpand, numpy, wldhx.yadisk-direct, webdataset, opencv-python-headless, opencv-python, torchmetrics, kornia, imgaug, pytorch-lightning, albumentations\n",
            "  Attempting uninstall: easydict\n",
            "    Found existing installation: easydict 1.13\n",
            "    Uninstalling easydict-1.13:\n",
            "      Successfully uninstalled easydict-1.13\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 2.0.8\n",
            "    Uninstalling albumentations-2.0.8:\n",
            "      Successfully uninstalled albumentations-2.0.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed albumentations-0.5.2 braceexpand-0.1.7 easydict-1.9 imgaug-0.4.0 kornia-0.5.0 numpy-1.26.4 opencv-python-4.11.0.86 opencv-python-headless-4.11.0.86 pytorch-lightning-1.2.9 torchmetrics-0.2.0 webdataset-1.0.2 wldhx.yadisk-direct-0.0.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "214b6a03a9f64d2f97b130d44563013a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade hydra-core==1.3.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbHP56YX709x",
        "outputId": "039d7a06-1841-4317-b14f-3ff5111919e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hydra-core==1.3.2\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core==1.3.2) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core==1.3.2) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core==1.3.2) (25.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.4,>=2.2->hydra-core==1.3.2) (6.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hydra-core\n",
            "Successfully installed hydra-core-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Parchear np.sctypes si no existe\n",
        "if not hasattr(np, \"sctypes\"):\n",
        "    np.sctypes = {\n",
        "        'int': [np.int8, np.int16, np.int32, np.int64],\n",
        "        'uint': [np.uint8, np.uint16, np.uint32, np.uint64],\n",
        "        'float': [np.float16, np.float32, np.float64],\n",
        "        'complex': [np.complex64, np.complex128]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "vCathsGk0_pm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descarga de los peso de YOLO V8"
      ],
      "metadata": {
        "id": "PemDIdl-Iear"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 3. Descargar pesos YOLO (ejemplo yolov8x-seg)\n",
        "# ==============================\n",
        "from ultralytics import YOLO\n",
        "YOLO(\"yolov8x-seg.pt\")  # descarga los pesos automáticamente"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_Tx3A0WxsTe",
        "outputId": "12ef0867-2181-4f02-affc-35bd9759ec7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x-seg.pt to 'yolov8x-seg.pt': 100% ━━━━━━━━━━━━ 137.4MB 128.8MB/s 1.1s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "YOLO(\n",
              "  (model): SegmentationModel(\n",
              "    (model): Sequential(\n",
              "      (0): Conv(\n",
              "        (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv(\n",
              "        (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (2): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-2): 3 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): Conv(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (4): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-5): 6 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): Conv(\n",
              "        (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (6): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-5): 6 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): Conv(\n",
              "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (8): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-2): 3 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): SPPF(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (11): Concat()\n",
              "      (12): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-2): 3 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (14): Concat()\n",
              "      (15): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-2): 3 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (16): Conv(\n",
              "        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (17): Concat()\n",
              "      (18): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-2): 3 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (19): Conv(\n",
              "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (20): Concat()\n",
              "      (21): C2f(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-2): 3 x Bottleneck(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (22): Segment(\n",
              "        (cv2): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (cv3): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (dfl): DFL(\n",
              "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "        (proto): Proto(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (upsample): ConvTranspose2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv4): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "747d1372"
      },
      "source": [
        "# !rm -rf /content/facade_model\n",
        "# !rm -rf /content/results\n",
        "# !rm -rf /content/pretrained_models"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clonar el repositorio"
      ],
      "metadata": {
        "id": "K6e0YnuYIkOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/wpradab/facade_model.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynyMIkmdQspp",
        "outputId": "a53905f7-987b-451c-cf26-b80140205169"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'facade_model'...\n",
            "remote: Enumerating objects: 636, done.\u001b[K\n",
            "remote: Counting objects: 100% (222/222), done.\u001b[K\n",
            "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
            "remote: Total 636 (delta 106), reused 170 (delta 56), pack-reused 414 (from 1)\u001b[K\n",
            "Receiving objects: 100% (636/636), 679.42 KiB | 14.15 MiB/s, done.\n",
            "Resolving deltas: 100% (170/170), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd facade_model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhoTg1NIA6bM",
        "outputId": "2f2d2192-f908-4674-a69f-00d0778c05e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/facade_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKOhWrF9HbBf",
        "outputId": "13a0ccdc-ca41-49a8-897f-28c5f967ee5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline_clean_select_houses.ipynb  requirements_python7_12.txt  test\n",
            "pyproject.toml\t\t\t    setup.cfg\n",
            "README.md\t\t\t    src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalar el repositorio sin las dependencias"
      ],
      "metadata": {
        "id": "dSYTViCOIoUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --no-deps git+https://github.com/wpradab/facade_model.git\n",
        "!pip install -e . --no-deps --force-reinstall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "X2S2GvdXFhS8",
        "outputId": "660847d6-77fa-4d34-b707-d44fbe28f0a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/facade_model\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: facade-model\n",
            "  Building editable for facade-model (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for facade-model: filename=facade_model-0.1.0-0.editable-py3-none-any.whl size=3522 sha256=98c4ff9445b0d3a6c76f321b78e315ee4f3a0757e586fedc5144312a4ae6348e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ht5wf0ae/wheels/68/21/6a/0a16851bbb964305ba738be8e839eb8d5516bbe938d209ef3b\n",
            "Successfully built facade-model\n",
            "Installing collected packages: facade-model\n",
            "  Attempting uninstall: facade-model\n",
            "    Found existing installation: facade-model 0.1.0\n",
            "    Uninstalling facade-model-0.1.0:\n",
            "      Successfully uninstalled facade-model-0.1.0\n",
            "Successfully installed facade-model-0.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "facade_model"
                ]
              },
              "id": "a56295baf2a34748b02fb0aa9cf3f79e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reiniciar sesión"
      ],
      "metadata": {
        "id": "Og0KJU2CXsn2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uso de las funciones del repositorio"
      ],
      "metadata": {
        "id": "IpswaEn1ItqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import facade_model\n",
        "print(dir(facade_model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH2LS6SoHsXR",
        "outputId": "6d2d527b-6c86-4e7d-a573-e2172beedfd6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detectron v2 is not installed\n",
            "['__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'extract_facade_metadata', 'find_house_in_image', 'house_selector', 'lama_inpaint', 'metadata_pipeline', 'object_removal', 'remove_objects_from_image', 'utils']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7svu14jVU4v8",
        "outputId": "4225ca28-ec00-4353-bab6-b401d6e2b1d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga de pesos de los modelos para las funciones"
      ],
      "metadata": {
        "id": "B__ollyNI-0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/IGAC/pretrained_models /content/pretrained_models"
      ],
      "metadata": {
        "id": "uR79eGNZVSOp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paso cero, extracción de metadata"
      ],
      "metadata": {
        "id": "XS2u8gXFJD7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from facade_model import remove_objects_from_image, find_house_in_image, extract_facade_metadata\n",
        "# 📂 Definir rutas de modelos\n",
        "model_path = \"yolov8x-seg.pt\"  # modelo YOLO para segmentación de objetos\n",
        "model_house_path = \"/content/pretrained_models/best.pt\"  # tu modelo de casas\n",
        "\n",
        "lama_config = \"/content/facade_model/src/facade_model/lama/configs/prediction/default.yaml\"\n",
        "lama_ckpt = \"/content/pretrained_models/big-lama\"\n",
        "\n",
        "target_labels = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'bus', 'train', 'truck',\n",
        "    'backpack', 'umbrella', 'handbag', 'suitcase', 'tree',\n",
        "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter',\n",
        "    'bench', 'chair', 'dog', 'cat', 'bird', 'couch',\n",
        "    'potted plant', 'dining table', 'teddy bear'\n",
        "]\n",
        "\n",
        "\n",
        "# 📂 1. Subir imágenes locales\n",
        "uploaded = files.upload()  # selecciona imagen desde tu PC\n",
        "image_path = list(uploaded.keys())[0]  # primera imagen subida\n",
        "\n",
        "# 🚀 Ejecutar función\n",
        "metadata = extract_facade_metadata(\n",
        "    image_path=image_path,\n",
        "    model_path=model_path,\n",
        "    model_house_path=model_house_path,\n",
        "    lama_config=lama_config,\n",
        "    lama_ckpt=lama_ckpt,\n",
        "    target_labels=target_labels,\n",
        ")\n",
        "\n",
        "print(\"✅ Metadata completa extraída:\")\n",
        "metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "C5gXjBDUD_dp",
        "outputId": "7b091c89-8cbf-4206-8260-c460a6885ebb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b2e2cd3f-1a1f-4d27-a801-8d68f4da34cf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b2e2cd3f-1a1f-4d27-a801-8d68f4da34cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 158350100000000-702_2023-09_27515.jpg to 158350100000000-702_2023-09_27515.jpg\n",
            "\n",
            "0: 480x640 (no detections), 4001.8ms\n",
            "Speed: 3.2ms preprocess, 4001.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 casas, 1 poste, 212.4ms\n",
            "Speed: 3.2ms preprocess, 212.4ms inference, 14.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 3 casas, 1 poste, 193.5ms\n",
            "Speed: 3.3ms preprocess, 193.5ms inference, 13.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ Metadata completa extraída:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metadata_remove_objects': {'image_name': '158350100000000-702_2023-09_27515',\n",
              "  'input_image': '158350100000000-702_2023-09_27515.jpg',\n",
              "  'detected_objects': [{'id': 2,\n",
              "    'class': 'poste',\n",
              "    'confidence': 0.745573878288269,\n",
              "    'bbox': [418.47760009765625, 16.24273681640625, 475.26983642578125, 480.0],\n",
              "    'mask_path': None}],\n",
              "  'output_mask': None,\n",
              "  'output_inpainted': None},\n",
              " 'metadata_incomplete_objects': {'image': '158350100000000-702_2023-09_27515.jpg',\n",
              "  'objects_count': {'casa': 3, 'poste': 1},\n",
              "  'selected_objects': {'casa': {'id': 0,\n",
              "    'area': 188351,\n",
              "    'center': (228, 242),\n",
              "    'box': [20.5745849609375, 5.2486572265625, 432.5010070800781, 480.0],\n",
              "    'touch_border': ['bottom'],\n",
              "    'incomplete': True},\n",
              "   'poste': {'id': 2,\n",
              "    'area': 15375,\n",
              "    'center': (449, 260),\n",
              "    'box': [418.47760009765625, 16.24273681640625, 475.26983642578125, 480.0],\n",
              "    'touch_border': ['bottom'],\n",
              "    'incomplete': True}}}}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remoción de objetos y selección de casa"
      ],
      "metadata": {
        "id": "BfvcvpIzJMx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📂 1. Subir imágenes locales\n",
        "uploaded = files.upload()  # selecciona imagen desde tu PC\n",
        "image_path = list(uploaded.keys())[0]  # primera imagen subida\n",
        "\n",
        "# 📂 2. Definir rutas de modelos\n",
        "model_path = \"yolov8x-seg.pt\"  # modelo YOLO para segmentación de objetos\n",
        "model_house_path = \"/content/pretrained_models/best.pt\"  # tu modelo de casas\n",
        "\n",
        "lama_config = \"/content/facade_model/src/facade_model/lama/configs/prediction/default.yaml\"\n",
        "lama_ckpt = \"/content/pretrained_models/big-lama\"\n",
        "\n",
        "# ==============================\n",
        "# 3. Ejecutar pipeline de remoción de objetos\n",
        "# ==============================\n",
        "target_labels = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'bus', 'train', 'truck',\n",
        "    'backpack', 'umbrella', 'handbag', 'suitcase', 'tree',\n",
        "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter',\n",
        "    'bench', 'chair', 'dog', 'cat', 'bird', 'couch',\n",
        "    'potted plant', 'dining table', 'teddy bear'\n",
        "]\n",
        "\n",
        "metadata_remove_objects = remove_objects_from_image(\n",
        "    image_path=image_path,\n",
        "    model_path=model_path,\n",
        "    post_model_path=model_house_path,\n",
        "    lama_config=lama_config,\n",
        "    lama_ckpt=lama_ckpt,\n",
        "    target_labels=target_labels,\n",
        "    base_output_dir=\"results\",\n",
        "    metadata_only=False\n",
        ")\n",
        "\n",
        "print(\"✅ Elementos eliminados\", metadata_remove_objects)\n",
        "\n",
        "# ==============================\n",
        "# 4. Selección de casas\n",
        "# ==============================\n",
        "metadata_incomplete_house = find_house_in_image(\n",
        "    image_path=image_path,\n",
        "    model_house_path=model_house_path,\n",
        "    results_dir=\"results\",\n",
        "    metadata_only=False\n",
        ")\n",
        "\n",
        "print(\"✅ Casa recortada:\", metadata_incomplete_house)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "NjgI48ynUvkQ",
        "outputId": "9e843443-9d2e-45e3-e3ed-f884448aa16a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fb3e955b-5408-4d71-af29-4916c6891136\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fb3e955b-5408-4d71-af29-4916c6891136\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 158350100000000210010000-132762_2023-09_21954.jpg to 158350100000000210010000-132762_2023-09_21954.jpg\n",
            "\n",
            "0: 480x640 1 car, 1 motorcycle, 1 dog, 4711.2ms\n",
            "Speed: 3.3ms preprocess, 4711.2ms inference, 15.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 casas, 1 poste, 196.0ms\n",
            "Speed: 3.6ms preprocess, 196.0ms inference, 15.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ Elementos eliminados {'image_name': '158350100000000210010000-132762_2023-09_21954', 'input_image': '158350100000000210010000-132762_2023-09_21954.jpg', 'detected_objects': [{'id': 0, 'class': 'car', 'confidence': 0.9471309185028076, 'bbox': [223.5482940673828, 317.9151916503906, 464.68975830078125, 432.4543762207031], 'mask_path': 'results/158350100000000210010000-132762_2023-09_21954/mask_0_car.png'}, {'id': 1, 'class': 'motorcycle', 'confidence': 0.9270852208137512, 'bbox': [46.6232795715332, 335.53076171875, 165.5290985107422, 402.0263671875], 'mask_path': 'results/158350100000000210010000-132762_2023-09_21954/mask_1_motorcycle.png'}, {'id': 2, 'class': 'dog', 'confidence': 0.707116961479187, 'bbox': [456.03515625, 328.68670654296875, 503.55096435546875, 374.06964111328125], 'mask_path': 'results/158350100000000210010000-132762_2023-09_21954/mask_2_dog.png'}, {'id': 2, 'class': 'poste', 'confidence': 0.7065779566764832, 'bbox': [502.87762451171875, 18.94439697265625, 526.3081665039062, 382.003662109375], 'mask_path': 'results/158350100000000210010000-132762_2023-09_21954/mask_2_poste.png'}], 'output_mask': 'results/158350100000000210010000-132762_2023-09_21954/mask_final.png', 'output_inpainted': 'results/158350100000000210010000-132762_2023-09_21954/inpainted.jpg'}\n",
            "\n",
            "0: 480x640 2 casas, 1 poste, 192.0ms\n",
            "Speed: 4.1ms preprocess, 192.0ms inference, 19.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "✅ Casa recortada: {'image': '158350100000000210010000-132762_2023-09_21954.jpg', 'objects_count': {'casa': 2, 'poste': 1}, 'selected_objects': {'casa': {'id': 0, 'area': 54119, 'center': (274, 275), 'box': [58.48698425292969, 211.58787536621094, 495.28839111328125, 361.8714599609375], 'touch_border': [], 'incomplete': False, 'mask_path': 'results/158350100000000210010000-132762_2023-09_21954_casa_mask.png', 'cropped_path': 'results/158350100000000210010000-132762_2023-09_21954_casa.jpg'}, 'poste': {'id': 2, 'area': 6540, 'center': (511, 204), 'box': [502.87762451171875, 18.94439697265625, 526.3081665039062, 382.003662109375], 'touch_border': [], 'incomplete': False, 'mask_path': 'results/158350100000000210010000-132762_2023-09_21954_poste_mask.png', 'cropped_path': 'results/158350100000000210010000-132762_2023-09_21954_poste.jpg'}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_incomplete_house"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShoBX4VwLsRh",
        "outputId": "354f18bf-2ec5-4eff-d47f-4ae1c640334d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': '158350100000000-851_2023-10_27664.jpg',\n",
              " 'objects_count': {'casa': 3, 'poste': 1},\n",
              " 'selected_objects': {'casa': {'id': 0,\n",
              "   'area': 120502,\n",
              "   'center': (310, 198),\n",
              "   'box': [94.606201171875,\n",
              "    45.546051025390625,\n",
              "    543.705078125,\n",
              "    401.3291320800781],\n",
              "   'touch_border': [],\n",
              "   'incomplete': False,\n",
              "   'mask_path': 'results/158350100000000-851_2023-10_27664_casa_mask.png',\n",
              "   'cropped_path': 'results/158350100000000-851_2023-10_27664_casa.jpg'},\n",
              "  'poste': {'id': 3,\n",
              "   'area': 7600,\n",
              "   'center': (138, 219),\n",
              "   'box': [125.10482025146484, 0.0, 153.27590942382812, 434.9033508300781],\n",
              "   'touch_border': ['top'],\n",
              "   'incomplete': True,\n",
              "   'mask_path': 'results/158350100000000-851_2023-10_27664_poste_mask.png',\n",
              "   'cropped_path': 'results/158350100000000-851_2023-10_27664_poste.jpg'}}}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_incomplete_house"
      ],
      "metadata": {
        "id": "MiykAXF9U_LR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cc314e-cf71-446e-9196-aa5bad119079"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': '158350100000000-799_2023-09_27612.jpg',\n",
              " 'objects_count': {'casa': 1, 'poste': 1},\n",
              " 'selected_objects': {'casa': {'id': 1,\n",
              "   'area': 7544,\n",
              "   'center': (616, 279),\n",
              "   'box': [593.6517333984375,\n",
              "    197.4659423828125,\n",
              "    639.72216796875,\n",
              "    358.7252197265625],\n",
              "   'touch_border': ['right'],\n",
              "   'incomplete': True,\n",
              "   'mask_path': 'results/158350100000000-799_2023-09_27612_casa_mask.png',\n",
              "   'cropped_path': 'results/158350100000000-799_2023-09_27612_casa.jpg'},\n",
              "  'poste': {'id': 0,\n",
              "   'area': 4978,\n",
              "   'center': (278, 191),\n",
              "   'box': [270.42730712890625,\n",
              "    13.639434814453125,\n",
              "    288.38909912109375,\n",
              "    347.66412353515625],\n",
              "   'touch_border': [],\n",
              "   'incomplete': False,\n",
              "   'mask_path': 'results/158350100000000-799_2023-09_27612_poste_mask.png',\n",
              "   'cropped_path': 'results/158350100000000-799_2023-09_27612_poste.jpg'}}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}